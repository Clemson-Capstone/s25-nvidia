include:
  - path: ./vectordb.yaml
  - path: ./nims.yaml
  - path: ./frontend.yaml
  - path: ./course-manager.yaml
  - path: ./prometheus-compose.yaml

services:
  rag-server:
    container_name: rag-server
    image: nvcr.io/nvidia/blueprint/rag-server:${TAG:-1.0.0}
    build:
      context: ../../foundational-rag
      dockerfile: src/Dockerfile
    command: --port 8081 --host 0.0.0.0 --workers 8
    environment:
      EXAMPLE_PATH: 'src/'
      APP_VECTORSTORE_URL: "http://milvus:19530"
      APP_VECTORSTORE_NAME: "milvus"
      APP_VECTORSTORE_INDEXTYPE: GPU_CAGRA
      COLLECTION_NAME: ${COLLECTION_NAME:-nvidia_blogs}
      APP_RETRIEVER_SCORETHRESHOLD: 0.25
      APP_LLM_MODELNAME: ${APP_LLM_MODELNAME:-"meta/llama-3.1-70b-instruct"}
      APP_LLM_SERVERURL: ${APP_LLM_SERVERURL:-""}
      APP_EMBEDDINGS_SERVERURL: ${APP_EMBEDDINGS_SERVERURL:-""}
      APP_EMBEDDINGS_MODELNAME: ${APP_EMBEDDINGS_MODELNAME:-nvidia/llama-3.2-nv-embedqa-1b-v2}
      APP_RANKING_SERVERURL: ${APP_RANKING_SERVERURL:-""}
      APP_RANKING_MODELNAME: ${APP_RANKING_MODELNAME:-"nvidia/llama-3.2-nv-rerankqa-1b-v2"}
      VECTOR_DB_TOPK: 20
      APP_TEXTSPLITTER_CHUNKSIZE: 2000
      APP_TEXTSPLITTER_CHUNKOVERLAP: 200
      NVIDIA_API_KEY: ${NVIDIA_API_KEY:?"NVIDIA_API_KEY is required"}
      APP_RETRIEVER_TOPK: 4
      LOGLEVEL: ${LOGLEVEL:-INFO}
      ENABLE_MULTITURN: ${ENABLE_MULTITURN:-true}
      ENABLE_QUERYREWRITER: ${ENABLE_QUERYREWRITER:-true}
      CONVERSATION_HISTORY: 5
      ENABLE_GUARDRAILS: ${ENABLE_GUARDRAILS:-true}
      GUARDRAILS_CONFIG_PATH: /app/src/guardrails
      GUARDRAILS_TEMPERATURE: ${GUARDRAILS_TEMPERATURE:-0.2}
    ports:
      - "8081:8081"
    expose:
      - "8081"
    volumes:
      - ../../foundational-rag/src:/app/src
      - ../../foundational-rag/src/guardrails:/app/src/guardrails:ro
    shm_size: 5gb
    depends_on:
      embedding-ms:
        condition: service_healthy
        required: false
      nemollm-inference:
        condition: service_healthy
        required: false

  rag-playground:
    container_name: rag-playground
    image: nvcr.io/nvidia/blueprint/rag-playground:${TAG:-1.0.0}
    build:
      context: ../../foundational-rag
      dockerfile: ./frontend/Dockerfile
    command: --port 8090
    environment:
      APP_SERVERURL: http://rag-server
      APP_SERVERPORT: 8081
      APP_MODELNAME: ${APP_LLM_MODELNAME:-"meta/llama-3.1-70b-instruct"}
    ports:
      - "8090:8090"
    expose:
      - "8090"
    depends_on:
      - rag-server

networks:
  default:
    name: nvidia-rag