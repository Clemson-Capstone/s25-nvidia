{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b998a5c-45a6-4f05-9c7c-b0f3c4c74c17",
   "metadata": {},
   "source": [
    "# Virtual Teaching Assistant NVIDIA AI Blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f2acb-52d9-49dd-9676-2d58715786f5",
   "metadata": {},
   "source": [
    "Imagine a teaching assistant that never sleeps, never gets tired, and is always ready to help. Our Virtual Teaching Assistant (VTA) makes that possible, transforming static educational content into dynamic learning experiences. Built for modern classrooms and self-learners alike, VTA is designed to:\n",
    "\n",
    "- Break down complex course materials into clear, conversational explanations\n",
    "\n",
    "- Guide students through material and help them arrive at answers on their own\n",
    "\n",
    "- Adapt its tone and depth based on user needs ‚Äî from quick summaries to in-depth walkthroughs\n",
    "\n",
    "- Utilize powerful language models via NVIDIA NIM to understand and explain academic content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd4f69",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"nvidiaragimg.png\" alt=\"NVIDIA RAG Diagram\" style=\"width:80%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af66273-f19d-4d4f-8480-31c5c03c5951",
   "metadata": {},
   "source": [
    "## Features\n",
    "Built on the NVIDIA RAG Blueprint, this system is optimized for fast setup, multimodal data handling, and private, on-prem inference or cloud deployment. Launch the full stack with a single make all. **We've built this for you to edit and deploy on your own infrastructure with ease.**\n",
    "\n",
    "#### Core Capabilities\n",
    "- **Canvas Integration  üìö** - The Course Manager API provides a RESTful interface to authenticate with Canvas, retrieve course data, and download materials. It integrates with the RAG server to enable AI-powered content processing.\n",
    "- **Guardrailed Conversations üõ°Ô∏è** - Uses NeMo Guardrails to maintain safe, educational, and on-topic assistant responses‚Äîideal for a classroom or learning environment.\n",
    "- **Multimodal Ingestion üìÑ** - Extracts text, tables, charts, and images from PDFs, DOCX, and PPTX files using GPU-accelerated NIM services.\n",
    "- **On-Prem LLM & Retrieval üß†** - Locally hosts embedding, reranking, and inference microservices using Meta Llama and NVIDIA models‚Äîensuring low latency and data privacy.\n",
    "- **Hybrid Semantic Search üåê** - Combines dense and sparse search for accurate academic content retrieval with support for multilingual queries.\n",
    "- **Context-Aware Responses üî•** - Supports multi-turn Q&A with reranking and query rewriting for enhanced dialogue quality.\n",
    "\n",
    "\n",
    "#### Development Experience\n",
    "- **One-Command Deployment ‚öôÔ∏è** - Launch ingestion, RAG, NIM services, and the playground UI with a single make all.\n",
    "- **Docker Compose Integration üê≥** - one command (`make all`) spins up the entire stack, with smart handling of GPU resources and service dependencies.\n",
    "\n",
    "\n",
    "#### Extend and Customize (More Information in nvidia-rag-2.0/docs)\n",
    "- **Swap Inference or Embedding Models üîÅ** - Easily change the LLM or embedding model to match your performance or domain needs.\n",
    "- **Customize Prompts and Parameters üéõÔ∏è** - Tailor prompt templates and LLM parameters at runtime for better control.\n",
    "- **Turn on Image Captioning üñºÔ∏è** - Add vision-language model support to describe visual content.\n",
    "- **Activate Hybrid Search üîç** - Combine sparse and dense retrieval to improve chunk relevance.\n",
    "- **Optimize for Text-Only Mode ‚ö°** - Reduce latency and compute for lightweight use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fcc47-fb41-4e54-9d30-4d17bc483779",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09678c9-8fbe-41d7-84ad-ce624bec582c",
   "metadata": {},
   "source": [
    "### Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197704e-b63c-42fc-be4b-4f3fb03acfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can skip this step if you just create the VM and can access it through ssh\n",
    "\n",
    "!git clone "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec102b-21d3-441c-a1a8-e72dbfc6c6fd",
   "metadata": {},
   "source": [
    "## Get an NVIDIA NIM Trial API Key\n",
    "\n",
    "Prior to getting started, you will need to create API Keys to access NVIDIA NIM trial hosted endpoints.\n",
    "\n",
    "If you don‚Äôt have an NVIDIA account, you will be asked to sign-up.\n",
    "\n",
    "Click [here](https://build.nvidia.com/meta/llama-3_3-70b-instruct?signin=true&api_key=true) to sign-in and get an API key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d68974-f114-4763-badb-9a158582f2e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> The key begins with the letters nvapi-."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc204aa9-8a1b-4cfe-82fd-ac35a0362407",
   "metadata": {},
   "source": [
    "## Set Environment Variables\n",
    "\n",
    "This notebook requires certain environment variables to be configured. We'll help you set these up in a `.env` file.\n",
    "\n",
    "Required variables:\n",
    "- `NVIDIA_API_KEY`: Your NVIDIA API key\n",
    "- `MAX_CONCURRENT_REQUESTS`: Number of concurrent requests allowed (recommended: 1 for local development)\n",
    "\n",
    "Run the code cell below to create your `.env` file. Make sure to replace the placeholder values with your actual API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d9aba6-f362-40fb-a0a7-eaf9e6641886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: cd: s25-nvidia/: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .env file. Please edit it with your actual API keys.\n",
      "\n",
      "Current .env contents:\n",
      "----------------------------------------\n",
      "NVIDIA_API_KEY=<ENTER_KEY>\n",
      "MAX_CONCURRENT_REQUESTS=1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd s25-nvidia/\n",
    "    \n",
    "# Backup existing .env if it exists\n",
    "if [ -f .env ]; then\n",
    "    echo \"Warning: .env file already exists. Backing up to .env.backup\"\n",
    "    mv .env .env.backup\n",
    "fi\n",
    "\n",
    "# Create new .env file\n",
    "cat > .env << EOL\n",
    "NVIDIA_API_KEY=<ENTER_KEY>\n",
    "MAX_CONCURRENT_REQUESTS=1\n",
    "EOL\n",
    "\n",
    "echo \"Created .env file. Please edit it with your actual API keys.\"\n",
    "echo -e \"\\nCurrent .env contents:\"\n",
    "echo \"----------------------------------------\"\n",
    "cat .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317ada1-3f8d-4e98-b07d-91cf2975498b",
   "metadata": {},
   "source": [
    "## Install Dependancies\n",
    "\n",
    "You can install them by simply running `make setup` in the root of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f1c4f-22f2-40da-9fad-fbaed4db8e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Cd into the repo\n",
    "cd s25-nvidia/ \n",
    "\n",
    "# Making setup script executable\n",
    "make setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7f3c4-d8c3-4b96-bb43-5c15c4c4918b",
   "metadata": {},
   "source": [
    "## Spin Up Blueprint\n",
    "Docker compose scripts are provided which spin up the microservices on a single node. This docker-compose yaml file will start up each microservice. This may take up to **15 minutes** to complete.\n",
    "\n",
    "> **In a separate terminal window, run**\n",
    "\n",
    "```\n",
    "cd s25-nvidia/\n",
    "make all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf647f-0f0b-45e2-959b-d96b013169a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps --format \"table {{.ID}}\\t{{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90c358-f0e9-4607-8b88-32a44ffce74e",
   "metadata": {},
   "source": [
    "This command should produce similiar output in the following format:\n",
    "\n",
    "```\n",
    "NAMES                                   STATUS\n",
    "compose-nv-ingest-ms-runtime-1          Up 5 minutes (healthy)\n",
    "ingestor-server                         Up 5 minutes\n",
    "compose-redis-1                         Up 5 minutes\n",
    "rag-playground                          Up 9 minutes\n",
    "rag-server                              Up 9 minutes\n",
    "milvus-standalone                       Up 36 minutes\n",
    "milvus-minio                            Up 35 minutes (healthy)\n",
    "milvus-etcd                             Up 35 minutes (healthy)\n",
    "nemoretriever-ranking-ms                Up 38 minutes (healthy)\n",
    "compose-page-elements-1                 Up 38 minutes\n",
    "compose-paddle-1                        Up 38 minutes\n",
    "compose-graphic-elements-1              Up 38 minutes\n",
    "compose-table-structure-1               Up 38 minutes\n",
    "nemoretriever-embedding-ms              Up 38 minutes (healthy)\n",
    "nim-llm-ms                              Up 38 minutes (healthy)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0d682-b20b-4dca-b966-db6605d9dadf",
   "metadata": {},
   "source": [
    "You can check if the services are up by running the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45f128-fe7e-4f9d-99bb-b23f8fbc4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl localhost:8002/health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6adb4c4",
   "metadata": {},
   "source": [
    "## Run the remaining commands for the course_manager_api and frontend service to be started up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e7949",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "# Try the make commands first \n",
    "run make frontend-compose\n",
    "run make api-start\n",
    "\n",
    "# If the course-manager-api service and the frontend is not showing up, then manually cd into their directories and run the following compose commands\n",
    "\n",
    "docker compose -f deploy/compose/course-manager.yaml up\n",
    "\n",
    "and\n",
    "\n",
    "docker compose -f deploy/compose/frontend.yaml up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c9bc5-6b6b-471a-b122-f029b20b2fdb",
   "metadata": {},
   "source": [
    "Open a web browser and access http://localhost:3000 to use our frontend. You can use the upload tab to ingest files into the server or follow the notebooks to understand the API usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e2e998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/Clemson-Capstone/s25-nvidia/main/docs/Dori_Frontend.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"https://raw.githubusercontent.com/Clemson-Capstone/s25-nvidia/main/docs/Dori_Frontend.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d76dd3",
   "metadata": {},
   "source": [
    "## If you have any questions or trouble running the brev launchable please feel free to leave a pull request for any fixes you know or reach out to the Clemson Team!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
