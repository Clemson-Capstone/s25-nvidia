{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b998a5c-45a6-4f05-9c7c-b0f3c4c74c17",
   "metadata": {},
   "source": [
    "# Virtual Teaching Assistant NVIDIA AI Blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f2acb-52d9-49dd-9676-2d58715786f5",
   "metadata": {},
   "source": [
    "Imagine a teaching assistant that never sleeps, never gets tired, and is always ready to help. Our Virtual Teaching Assistant (VTA) makes that possible, transforming static educational content into dynamic learning experiences. Built for modern classrooms and self-learners alike, VTA is designed to:\n",
    "\n",
    "- Break down complex course materials into clear, conversational explanations\n",
    "\n",
    "- Guide students through material and help them arrive at answers on their own\n",
    "\n",
    "- Adapt its tone and depth based on user needs ‚Äî from quick summaries to in-depth walkthroughs\n",
    "\n",
    "- Utilize powerful language models via NVIDIA NIM to understand and explain academic content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd4f69",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"nvidiaragimg.png\" alt=\"NVIDIA RAG Diagram\" style=\"width:80%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af66273-f19d-4d4f-8480-31c5c03c5951",
   "metadata": {},
   "source": [
    "## Features\n",
    "Built on the NVIDIA RAG Blueprint, this system is optimized for fast setup, multimodal data handling, and private, on-prem inference or cloud deployment. Launch the full stack with a single make all. **We've built this for you to edit and deploy on your own infrastructure with ease.**\n",
    "\n",
    "#### Core Capabilities\n",
    "- **Canvas Integration  üìö** - The Course Manager API provides a RESTful interface to authenticate with Canvas, retrieve course data, and download materials. It integrates with the RAG server to enable AI-powered content processing.\n",
    "- **Guardrailed Conversations üõ°Ô∏è** - Uses NeMo Guardrails to maintain safe, educational, and on-topic assistant responses‚Äîideal for a classroom or learning environment.\n",
    "- **Multimodal Ingestion üìÑ** - Extracts text, tables, charts, and images from PDFs, DOCX, and PPTX files using GPU-accelerated NIM services.\n",
    "- **On-Prem LLM & Retrieval üß†** - Locally hosts embedding, reranking, and inference microservices using Meta Llama and NVIDIA models‚Äîensuring low latency and data privacy.\n",
    "- **Hybrid Semantic Search üåê** - Combines dense and sparse search for accurate academic content retrieval with support for multilingual queries.\n",
    "- **Context-Aware Responses üî•** - Supports multi-turn Q&A with reranking and query rewriting for enhanced dialogue quality.\n",
    "\n",
    "\n",
    "#### Development Experience\n",
    "- **One-Command Deployment ‚öôÔ∏è** - Launch ingestion, RAG, NIM services, and the playground UI with a single make all.\n",
    "- **Docker Compose Integration üê≥** - one command (`make all`) spins up the entire stack, with smart handling of GPU resources and service dependencies.\n",
    "\n",
    "\n",
    "#### Extend and Customize (More Information in nvidia-rag-2.0/docs)\n",
    "- **Swap Inference or Embedding Models üîÅ** - Easily change the LLM or embedding model to match your performance or domain needs.\n",
    "- **Customize Prompts and Parameters üéõÔ∏è** - Tailor prompt templates and LLM parameters at runtime for better control.\n",
    "- **Turn on Image Captioning üñºÔ∏è** - Add vision-language model support to describe visual content.\n",
    "- **Activate Hybrid Search üîç** - Combine sparse and dense retrieval to improve chunk relevance.\n",
    "- **Optimize for Text-Only Mode ‚ö°** - Reduce latency and compute for lightweight use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fcc47-fb41-4e54-9d30-4d17bc483779",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09678c9-8fbe-41d7-84ad-ce624bec582c",
   "metadata": {},
   "source": [
    "### Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197704e-b63c-42fc-be4b-4f3fb03acfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can skip this step if you just create the VM and can access it through ssh\n",
    "\n",
    "!git clone "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec102b-21d3-441c-a1a8-e72dbfc6c6fd",
   "metadata": {},
   "source": [
    "## Get an NVIDIA NIM Trial API Key\n",
    "\n",
    "Prior to getting started, you will need to create API Keys to access NVIDIA NIM trial hosted endpoints.\n",
    "\n",
    "If you don‚Äôt have an NVIDIA account, you will be asked to sign-up.\n",
    "\n",
    "Click [here](https://build.nvidia.com/meta/llama-3_3-70b-instruct?signin=true&api_key=true) to sign-in and get an API key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d68974-f114-4763-badb-9a158582f2e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> The key begins with the letters nvapi-."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc204aa9-8a1b-4cfe-82fd-ac35a0362407",
   "metadata": {},
   "source": [
    "## Set Environment Variables\n",
    "\n",
    "This notebook requires certain environment variables to be configured. We'll help you set these up in a `.env` file.\n",
    "\n",
    "Required variables:\n",
    "- `NVIDIA_API_KEY`: Your NVIDIA API key\n",
    "- `MAX_CONCURRENT_REQUESTS`: Number of concurrent requests allowed (recommended: 1 for local development)\n",
    "\n",
    "Run the code cell below to create your `.env` file. Make sure to replace the placeholder values with your actual API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d9aba6-f362-40fb-a0a7-eaf9e6641886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: cd: s25-nvidia/: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .env file. Please edit it with your actual API keys.\n",
      "\n",
      "Current .env contents:\n",
      "----------------------------------------\n",
      "NVIDIA_API_KEY=<ENTER_KEY>\n",
      "MAX_CONCURRENT_REQUESTS=1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd s25-nvidia/\n",
    "    \n",
    "# Backup existing .env if it exists\n",
    "if [ -f .env ]; then\n",
    "    echo \"Warning: .env file already exists. Backing up to .env.backup\"\n",
    "    mv .env .env.backup\n",
    "fi\n",
    "\n",
    "# Create new .env file\n",
    "cat > .env << EOL\n",
    "NVIDIA_API_KEY=<ENTER_KEY>\n",
    "MAX_CONCURRENT_REQUESTS=1\n",
    "EOL\n",
    "\n",
    "echo \"Created .env file. Please edit it with your actual API keys.\"\n",
    "echo -e \"\\nCurrent .env contents:\"\n",
    "echo \"----------------------------------------\"\n",
    "cat .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317ada1-3f8d-4e98-b07d-91cf2975498b",
   "metadata": {},
   "source": [
    "## Install Dependancies\n",
    "\n",
    "You can install them by simply running `make setup` in the root of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f1c4f-22f2-40da-9fad-fbaed4db8e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 3: cd: s25-nvidia/: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n# Cd into the repo\\ncd s25-nvidia/ \\n\\n# Making setup script executable\\nmake setup > /dev/null 2>&1\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Cd into the repo\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcd s25-nvidia/ \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Making setup script executable\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmake setup > /dev/null 2>&1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/magics/script.py:154\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/magics/script.py:314\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\n# Cd into the repo\\ncd s25-nvidia/ \\n\\n# Making setup script executable\\nmake setup > /dev/null 2>&1\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Cd into the repo\n",
    "cd s25-nvidia/ \n",
    "\n",
    "# Making setup script executable\n",
    "make setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7f3c4-d8c3-4b96-bb43-5c15c4c4918b",
   "metadata": {},
   "source": [
    "## Spin Up Blueprint\n",
    "Docker compose scripts are provided which spin up the microservices on a single node. This docker-compose yaml file will start up each microservice. This may take up to **15 minutes** to complete.\n",
    "\n",
    "> **In a separate terminal window, run**\n",
    "\n",
    "```\n",
    "cd s25-nvidia/\n",
    "make all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf647f-0f0b-45e2-959b-d96b013169a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps --format \"table {{.ID}}\\t{{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90c358-f0e9-4607-8b88-32a44ffce74e",
   "metadata": {},
   "source": [
    "This command should produce similiar output in the following format:\n",
    "\n",
    "```\n",
    "NAMES                                   STATUS\n",
    "compose-nv-ingest-ms-runtime-1          Up 5 minutes (healthy)\n",
    "ingestor-server                         Up 5 minutes\n",
    "compose-redis-1                         Up 5 minutes\n",
    "rag-playground                          Up 9 minutes\n",
    "rag-server                              Up 9 minutes\n",
    "milvus-standalone                       Up 36 minutes\n",
    "milvus-minio                            Up 35 minutes (healthy)\n",
    "milvus-etcd                             Up 35 minutes (healthy)\n",
    "nemoretriever-ranking-ms                Up 38 minutes (healthy)\n",
    "compose-page-elements-1                 Up 38 minutes\n",
    "compose-paddle-1                        Up 38 minutes\n",
    "compose-graphic-elements-1              Up 38 minutes\n",
    "compose-table-structure-1               Up 38 minutes\n",
    "nemoretriever-embedding-ms              Up 38 minutes (healthy)\n",
    "nim-llm-ms                              Up 38 minutes (healthy)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0d682-b20b-4dca-b966-db6605d9dadf",
   "metadata": {},
   "source": [
    "You can check if the services are up by running the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45f128-fe7e-4f9d-99bb-b23f8fbc4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl localhost:8002/health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6adb4c4",
   "metadata": {},
   "source": [
    "## Run the remaining commands for the course_manager_api and frontend service to be started up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e7949",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "# Try the make commands first \n",
    "run make frontend-compose\n",
    "run make api-start\n",
    "\n",
    "# If the course-manager-api service and the frontend is not showing up, then manually cd into their directories and run the following compose commands\n",
    "\n",
    "docker compose -f deploy/compose/course-manager.yaml up\n",
    "\n",
    "and\n",
    "\n",
    "docker compose -f deploy/compose/frontend.yaml up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c9bc5-6b6b-471a-b122-f029b20b2fdb",
   "metadata": {},
   "source": [
    "Open a web browser and access http://localhost:3000 to use our frontend. You can use the upload tab to ingest files into the server or follow the notebooks to understand the API usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e2e998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/Clemson-Capstone/s25-nvidia/main/docs/Dori_Frontend.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"https://raw.githubusercontent.com/Clemson-Capstone/s25-nvidia/main/docs/Dori_Frontend.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d76dd3",
   "metadata": {},
   "source": [
    "## If you have any questions or trouble running the brev launchable please feel free to leave a pull request for any fixes you know or reach out to the Clemson Team!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
